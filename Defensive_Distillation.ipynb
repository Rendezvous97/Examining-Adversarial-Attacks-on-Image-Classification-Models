{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Defensive_Distillation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "r1yQ3U4pmtE4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Defensive Distillation for LFW"
      ]
    },
    {
      "metadata": {
        "id": "nBAmVGHV46h6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad0a23da-cbfe-47b0-e3f7-6a1bdb6d8dca"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import Model\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from keras.layers import Input\n",
        "from keras.layers import Conv2D, GlobalAvgPool2D\n",
        "from keras.layers import Dropout, Activation\n",
        "class LFW:\n",
        "  def __init__(self):\n",
        "    test_split = 0.2\n",
        "    lfw_people = fetch_lfw_people(min_faces_per_person=35, color=True, resize=1.0,\n",
        "                              slice_=(slice(48, 202), slice(48, 202)))\n",
        "\n",
        "    self.X = lfw_people.images\n",
        "    self.y = lfw_people.target\n",
        "    target_names = lfw_people.target_names\n",
        "    self.n_classes = target_names.shape[0]\n",
        "    # train/test split\n",
        "    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=test_split, \n",
        "                                                        stratify=self.y, random_state=42)\n",
        "\n",
        "    # oversampling each class to contain at least 256 examples\n",
        "    sampling_targets = np.maximum([256] * self.n_classes, np.bincount(self.y_train))\n",
        "    ratio_dict = dict(zip(range(self.n_classes), sampling_targets))\n",
        "    ros = RandomOverSampler(ratio=ratio_dict, random_state=42)\n",
        "\n",
        "    self.X_train_shape = self.X_train.shape\n",
        "    self.X_train = np.reshape(self.X_train, (self.X_train_shape[0], -1))\n",
        "    self.X_train, self.y_train = ros.fit_sample(self.X_train, self.y_train)\n",
        "    self.X_train = np.reshape(self.X_train, (len(self.X_train),) + self.X_train_shape[1:])\n",
        "\n",
        "    # one-hot encoding of labels\n",
        "    self.y_train = keras.utils.to_categorical(self.y_train, self.n_classes)\n",
        "    self.y_test = keras.utils.to_categorical(self.y_test, self.n_classes)\n",
        "    \n",
        "    "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0NIDFbm8AHLh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "def train_lfw(data, num_epochs=100, batch_size=256, train_temp=1, init=None):\n",
        "  datagen = ImageDataGenerator(\n",
        "      rotation_range=10,\n",
        "      width_shift_range=0.1,\n",
        "      height_shift_range=0.1,\n",
        "      shear_range=0.05,\n",
        "      zoom_range=0.1)\n",
        "  test_split = 0.2\n",
        "  base_lr = 0.001\n",
        "  input = Input(shape=data.X.shape[1:])                                  # 154x154x3\n",
        "  x = Conv2D(12, (3, 3), padding='same', activation='relu')(input)  # 154x154x12\n",
        "  x = Conv2D(12, (2, 2), strides=(2, 2), activation='relu')(x)      # 77x77x12\n",
        "  x = Conv2D(16, (3, 3), padding='same', activation='relu')(x)      # 77x77x16\n",
        "  x = Conv2D(16, (2, 2), strides=(2, 2), activation='relu')(x)      # 38x38x16\n",
        "  x = Conv2D(24, (3, 3), padding='same', activation='relu')(x)      # 38x38x24\n",
        "  x = Conv2D(24, (2, 2), strides=(2, 2), activation='relu')(x)      # 19x19x24\n",
        "  x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)      # 19x19x32\n",
        "  x = Conv2D(32, (2, 2), strides=(2, 2), activation='relu')(x)      # 9x9x32\n",
        "  x = Conv2D(48, (3, 3), padding='same', activation='relu')(x)      # 9x9x48\n",
        "  x = Conv2D(48, (2, 2), strides=(2, 2), activation='relu')(x)      # 4x4x48\n",
        "  x = Dropout(0.5)(x)                                               # 4x4x48\n",
        "  x = Conv2D(data.n_classes, (1, 1))(x)                                  # 4x4x62\n",
        "  x = GlobalAvgPool2D()(x)                                          # 62\n",
        "  output = Activation('softmax')(x) \n",
        "  model = Model(inputs=input, outputs=output)\n",
        "  \n",
        "  def fn(correct, predicted):\n",
        "#         print(predicted)\n",
        "        return tf.nn.softmax_cross_entropy_with_logits(labels=correct,\n",
        "                                                       logits=predicted/train_temp)\n",
        "  sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  model.compile(loss=fn,\n",
        "                optimizer= keras.optimizers.Nadam(lr=base_lr),\n",
        "                metrics=['accuracy'])\n",
        "  history = model.fit_generator(datagen.flow(data.X_train, data.y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=len(data.X_train) / batch_size,\n",
        "                    epochs=num_epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(data.X_test, data.y_test))\n",
        "  \n",
        "#   model.load_weights('weights100epochs.h5')\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fVGKxU4sGGWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "a129e558-8afb-4746-fb3a-f080401529ec"
      },
      "cell_type": "code",
      "source": [
        "lfw_model = train_lfw(LFW())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-68a90198aab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlfw_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lfw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLFW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-3bc4a7b6ee9c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtest_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     lfw_people = fetch_lfw_people(min_faces_per_person=35, color=True, resize=1.0,\n\u001b[0;32m---> 17\u001b[0;31m                               slice_=(slice(48, 202), slice(48, 202)))\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlfw_people\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/datasets/lfw.py\u001b[0m in \u001b[0;36mfetch_lfw_people\u001b[0;34m(data_home, funneled, resize, min_faces_per_person, color, slice_, download_if_missing, return_X_y)\u001b[0m\n\u001b[1;32m    339\u001b[0m     faces, target, target_names = load_func(\n\u001b[1;32m    340\u001b[0m         \u001b[0mdata_folder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         min_faces_per_person=min_faces_per_person, color=color, slice_=slice_)\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(self, args, kwargs, shelving)\u001b[0m\n\u001b[1;32m    501\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mfunc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m                         \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m                         verbose=self._verbose)\n\u001b[0m\u001b[1;32m    504\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_store_backends.py\u001b[0m in \u001b[0;36mload_item\u001b[0;34m(self, path, verbose, msg)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmmap_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
            "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1048\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDArrayWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;31m# Be careful to register our new method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, unpickler)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Manage array subclass case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(self, unpickler)\u001b[0m\n\u001b[1;32m    144\u001b[0m                     \u001b[0mread_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_count\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                     data = _read_bytes(unpickler.file_handle,\n\u001b[0;32m--> 146\u001b[0;31m                                        read_size, \"array data\")\n\u001b[0m\u001b[1;32m    147\u001b[0m                     \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mread_count\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                         unpickler.np.frombuffer(data, dtype=self.dtype,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/numpy_pickle_utils.py\u001b[0m in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;31m# done about that.  note that regular files can't be non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/compressor.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \"\"\"\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBufferedIOBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/compressor.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/compressor.py\u001b[0m in \u001b[0;36m_read_block\u001b[0;34m(self, n_bytes, return_data)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0mn_bytes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fill_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_bytes\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_bytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/compressor.py\u001b[0m in \u001b[0;36m_fill_buffer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Zb0bcTxLNByF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_distillation_lfw(data, num_epochs=50, batch_size=128, train_temp=1):\n",
        "    \"\"\"\n",
        "    Train a network using defensive distillation.\n",
        "    Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks\n",
        "    Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, Ananthram Swami\n",
        "    IEEE S&P, 2016.\n",
        "    \"\"\"\n",
        "#     if not os.path.exists(file_name+\"_init\"):\n",
        "#         # Train for one epoch to get a good starting point.\n",
        "#         train(data, 1, batch_size)\n",
        "    \n",
        "    # now train the teacher at the given temperature\n",
        "    teacher = train_lfw(data, num_epochs, batch_size, train_temp)\n",
        "\n",
        "    # evaluate the labels at temperature t\n",
        "    predicted = teacher.predict(data.X_train)\n",
        "    with tf.Session() as sess:\n",
        "        y = sess.run(tf.nn.softmax(predicted/train_temp))\n",
        "        print(y)\n",
        "        data.y_train = y\n",
        "\n",
        "    # train the student model at temperature t\n",
        "    student = train_lfw(data, num_epochs, batch_size, train_temp)\n",
        "\n",
        "    # and finally we predict at temperature 1\n",
        "    predicted = student.predict(data.X_train)\n",
        "\n",
        "    print(predicted)\n",
        "    \n",
        "    return student\n",
        "    \n",
        "# if not os.path.isdir('models'):\n",
        "#     os.makedirs('models')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OEURhnwZPHIc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "a01eb6fe-98b0-4c46-e824-26947510cf58"
      },
      "cell_type": "code",
      "source": [
        "lfw_distillation_model = train_distillation_lfw(LFW(), train_temp=5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "50/49 [==============================] - 29s 578ms/step - loss: 3.1755 - acc: 0.0575 - val_loss: 3.1357 - val_acc: 0.2579\n",
            "Epoch 2/50\n",
            "50/49 [==============================] - 27s 548ms/step - loss: 3.1738 - acc: 0.0669 - val_loss: 3.1357 - val_acc: 0.2579\n",
            "Epoch 3/50\n",
            "50/49 [==============================] - 28s 560ms/step - loss: 3.1738 - acc: 0.0673 - val_loss: 3.1357 - val_acc: 0.2579\n",
            "Epoch 4/50\n",
            "50/49 [==============================] - 28s 566ms/step - loss: 3.1737 - acc: 0.0676 - val_loss: 3.1357 - val_acc: 0.2579\n",
            "Epoch 5/50\n",
            "46/49 [==========================>...] - ETA: 1s - loss: 3.1738 - acc: 0.0671"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0d9d38830114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlfw_distillation_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_distillation_lfw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLFW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_temp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-7ae401cb9c24>\u001b[0m in \u001b[0;36mtrain_distillation_lfw\u001b[0;34m(data, num_epochs, batch_size, train_temp)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# now train the teacher at the given temperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mteacher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lfw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# evaluate the labels at temperature t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-408ee8c7be7d>\u001b[0m in \u001b[0;36mtrain_lfw\u001b[0;34m(data, num_epochs, batch_size, train_temp, init)\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     validation_data=(data.X_test, data.y_test))\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m#   model.load_weights('weights100epochs.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "p5OSlxInmcII",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Defensive Distillation for MNIST and CIFAR"
      ]
    },
    {
      "metadata": {
        "id": "F5_Ji50xAHI2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import gzip\n",
        "import pickle\n",
        "import urllib.request\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.models import load_model\n",
        "\n",
        "def load_batch(fpath, label_key='labels'):\n",
        "    f = open(fpath, 'rb')\n",
        "    d = pickle.load(f, encoding=\"bytes\")\n",
        "    for k, v in d.items():\n",
        "        del(d[k])\n",
        "        d[k.decode(\"utf8\")] = v\n",
        "    f.close()\n",
        "    data = d[\"data\"]\n",
        "    labels = d[label_key]\n",
        "\n",
        "    data = data.reshape(data.shape[0], 3, 32, 32)\n",
        "    final = np.zeros((data.shape[0], 32, 32, 3),dtype=np.float32)\n",
        "    final[:,:,:,0] = data[:,0,:,:]\n",
        "    final[:,:,:,1] = data[:,1,:,:]\n",
        "    final[:,:,:,2] = data[:,2,:,:]\n",
        "\n",
        "    final /= 255\n",
        "    final -= .5\n",
        "    labels2 = np.zeros((len(labels), 10))\n",
        "    labels2[np.arange(len(labels2)), labels] = 1\n",
        "\n",
        "    return final, labels\n",
        "\n",
        "def load_batch(fpath):\n",
        "    f = open(fpath,\"rb\").read()\n",
        "    size = 32*32*3+1\n",
        "    labels = []\n",
        "    images = []\n",
        "    for i in range(10000):\n",
        "        arr = np.fromstring(f[i*size:(i+1)*size],dtype=np.uint8)\n",
        "        lab = np.identity(10)[arr[0]]\n",
        "        img = arr[1:].reshape((3,32,32)).transpose((1,2,0))\n",
        "\n",
        "        labels.append(lab)\n",
        "        images.append((img/255)-.5)\n",
        "    return np.array(images),np.array(labels)\n",
        "    \n",
        "\n",
        "class CIFAR:\n",
        "    def __init__(self):\n",
        "        train_data = []\n",
        "        train_labels = []\n",
        "        \n",
        "        if not os.path.exists(\"cifar-10-batches-bin\"):\n",
        "            urllib.request.urlretrieve(\"https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\",\n",
        "                                       \"cifar-data.tar.gz\")\n",
        "            os.popen(\"tar -xzf cifar-data.tar.gz\").read()\n",
        "            \n",
        "\n",
        "        for i in range(5):\n",
        "            r,s = load_batch(\"cifar-10-batches-bin/data_batch_\"+str(i+1)+\".bin\")\n",
        "            train_data.extend(r)\n",
        "            train_labels.extend(s)\n",
        "            \n",
        "        train_data = np.array(train_data,dtype=np.float32)\n",
        "        train_labels = np.array(train_labels)\n",
        "        \n",
        "        self.test_data, self.test_labels = load_batch(\"cifar-10-batches-bin/test_batch.bin\")\n",
        "        \n",
        "        VALIDATION_SIZE = 5000\n",
        "        \n",
        "        self.validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n",
        "        self.validation_labels = train_labels[:VALIDATION_SIZE]\n",
        "        self.train_data = train_data[VALIDATION_SIZE:, :, :, :]\n",
        "        self.train_labels = train_labels[VALIDATION_SIZE:]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F0JkIVTjUhBd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import gzip\n",
        "import urllib.request\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.models import load_model\n",
        "\n",
        "def extract_data(filename, num_images):\n",
        "    with gzip.open(filename) as bytestream:\n",
        "        bytestream.read(16)\n",
        "        buf = bytestream.read(num_images*28*28)\n",
        "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
        "        data = (data / 255) - 0.5\n",
        "        data = data.reshape(num_images, 28, 28, 1)\n",
        "        return data\n",
        "\n",
        "def extract_labels(filename, num_images):\n",
        "    with gzip.open(filename) as bytestream:\n",
        "        bytestream.read(8)\n",
        "        buf = bytestream.read(1 * num_images)\n",
        "        labels = np.frombuffer(buf, dtype=np.uint8)\n",
        "    return (np.arange(10) == labels[:, None]).astype(np.float32)\n",
        "\n",
        "class MNIST:\n",
        "    def __init__(self):\n",
        "        if not os.path.exists(\"data\"):\n",
        "            os.mkdir(\"data\")\n",
        "            files = [\"train-images-idx3-ubyte.gz\",\n",
        "                     \"t10k-images-idx3-ubyte.gz\",\n",
        "                     \"train-labels-idx1-ubyte.gz\",\n",
        "                     \"t10k-labels-idx1-ubyte.gz\"]\n",
        "            for name in files:\n",
        "\n",
        "                urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/' + name, \"data/\"+name)\n",
        "\n",
        "        train_data = extract_data(\"data/train-images-idx3-ubyte.gz\", 60000)\n",
        "        train_labels = extract_labels(\"data/train-labels-idx1-ubyte.gz\", 60000)\n",
        "        self.test_data = extract_data(\"data/t10k-images-idx3-ubyte.gz\", 10000)\n",
        "        self.test_labels = extract_labels(\"data/t10k-labels-idx1-ubyte.gz\", 10000)\n",
        "        \n",
        "        VALIDATION_SIZE = 5000\n",
        "        \n",
        "        self.validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n",
        "        self.validation_labels = train_labels[:VALIDATION_SIZE]\n",
        "        self.train_data = train_data[VALIDATION_SIZE:, :, :, :]\n",
        "        self.train_labels = train_labels[VALIDATION_SIZE:]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gxkoQTDqVWAn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "import tensorflow as tf\n",
        "# from setup_mnist import MNIST\n",
        "# from setup_cifar import CIFAR\n",
        "import os\n",
        "\n",
        "def train(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1, init=None):\n",
        "    \"\"\"\n",
        "    Standard neural network training procedure.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    print(data.train_data.shape)\n",
        "    \n",
        "    model.add(Conv2D(params[0], (3, 3),\n",
        "                            input_shape=data.train_data.shape[1:]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(params[1], (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(params[2], (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(params[3], (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(params[4]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(params[5]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(10))\n",
        "    \n",
        "    if init != None:\n",
        "        model.load_weights(init)\n",
        "\n",
        "    def fn(correct, predicted):\n",
        "        return tf.nn.softmax_cross_entropy_with_logits(labels=correct,\n",
        "                                                       logits=predicted/train_temp)\n",
        "\n",
        "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    \n",
        "    model.compile(loss=fn,\n",
        "                  optimizer=sgd,\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    model.fit(data.train_data, data.train_labels,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(data.validation_data, data.validation_labels),\n",
        "              nb_epoch=num_epochs,\n",
        "              shuffle=True)\n",
        "    \n",
        "\n",
        "    if file_name != None:\n",
        "        model.save(file_name)\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_distillation(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1):\n",
        "    \"\"\"\n",
        "    Train a network using defensive distillation.\n",
        "    Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks\n",
        "    Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, Ananthram Swami\n",
        "    IEEE S&P, 2016.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(file_name+\"_init\"):\n",
        "        # Train for one epoch to get a good starting point.\n",
        "        train(data, file_name+\"_init\", params, 1, batch_size)\n",
        "    \n",
        "    # now train the teacher at the given temperature\n",
        "    teacher = train(data, file_name+\"_teacher\", params, num_epochs, batch_size, train_temp,\n",
        "                    init=file_name+\"_init\")\n",
        "\n",
        "    # evaluate the labels at temperature t\n",
        "    predicted = teacher.predict(data.train_data)\n",
        "    with tf.Session() as sess:\n",
        "        y = sess.run(tf.nn.softmax(predicted/train_temp))\n",
        "        print(y)\n",
        "        data.train_labels = y\n",
        "\n",
        "    # train the student model at temperature t\n",
        "    student = train(data, file_name, params, num_epochs, batch_size, train_temp,\n",
        "                    init=file_name+\"_init\")\n",
        "\n",
        "    # and finally we predict at temperature 1\n",
        "    predicted = student.predict(data.train_data)\n",
        "\n",
        "#     print(predicted)\n",
        "    return student\n",
        "    \n",
        "if not os.path.isdir('models'):\n",
        "    os.makedirs('models')\n",
        "\n",
        "# cifar_model = train(CIFAR(), \"models/cifar\", [64, 64, 128, 128, 256, 256], num_epochs=50)\n",
        "# mnist_model = train(MNIST(), \"models/mnist\", [32, 32, 64, 64, 200, 200], num_epochs=12)\n",
        "\n",
        "# train_distillation(MNIST(), \"models/mnist-distilled-100\", [32, 32, 64, 64, 200, 200],\n",
        "#                    num_epochs=50, train_temp=100)\n",
        "# train_distillation(CIFAR(), \"models/cifar-distilled-100\", [64, 64, 128, 128, 256, 256],\n",
        "#                    num_epochs=50, train_temp=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s3d90OwaAv5Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "aabd4e5c-a407-43b8-b37d-682f900fda57"
      },
      "cell_type": "code",
      "source": [
        "mnist_model = train(MNIST(), \"models/mnist\", [32, 32, 64, 64, 200, 200], num_epochs=12)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(55000, 28, 28, 1)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From <ipython-input-4-e8e7e4acbe2e>:46: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/12\n",
            "55000/55000 [==============================] - 9s 158us/step - loss: 0.7027 - acc: 0.7663 - val_loss: 0.0930 - val_acc: 0.9716\n",
            "Epoch 2/12\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.1261 - acc: 0.9618 - val_loss: 0.0626 - val_acc: 0.9816\n",
            "Epoch 3/12\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0861 - acc: 0.9742 - val_loss: 0.0492 - val_acc: 0.9878\n",
            "Epoch 4/12\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0672 - acc: 0.9798 - val_loss: 0.0473 - val_acc: 0.9866\n",
            "Epoch 5/12\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0573 - acc: 0.9828 - val_loss: 0.0450 - val_acc: 0.9874\n",
            "Epoch 6/12\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0490 - acc: 0.9847 - val_loss: 0.0411 - val_acc: 0.9900\n",
            "Epoch 7/12\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0436 - acc: 0.9869 - val_loss: 0.0351 - val_acc: 0.9902\n",
            "Epoch 8/12\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0394 - acc: 0.9878 - val_loss: 0.0371 - val_acc: 0.9904\n",
            "Epoch 9/12\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0352 - acc: 0.9893 - val_loss: 0.0369 - val_acc: 0.9912\n",
            "Epoch 10/12\n",
            "55000/55000 [==============================] - 3s 59us/step - loss: 0.0313 - acc: 0.9904 - val_loss: 0.0344 - val_acc: 0.9922\n",
            "Epoch 11/12\n",
            "55000/55000 [==============================] - 3s 59us/step - loss: 0.0281 - acc: 0.9908 - val_loss: 0.0337 - val_acc: 0.9934\n",
            "Epoch 12/12\n",
            "55000/55000 [==============================] - 3s 61us/step - loss: 0.0279 - acc: 0.9915 - val_loss: 0.0320 - val_acc: 0.9920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eEV8KmtebKnb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "e97dc98c-6afb-4246-aae9-3b04af419b9d"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "data = MNIST()\n",
        "print(data.validation_data[0].shape)\n",
        "# print(mnist_model.predict(data.validation_data[0]))\n",
        "\n",
        "img = image.load_img(\"3_hack.png\", color_mode = \"grayscale\", target_size=((28, 28)))\n",
        "original_image = image.img_to_array(img)\n",
        "print(original_image.shape)\n",
        "\n",
        "og = np.expand_dims(original_image, axis=0)\n",
        "\n",
        "print(mnist_model.predict(og))\n",
        "print(data.validation_labels[0])\n",
        "\n",
        "plot_img = original_image.reshape((28,28))\n",
        "plot_img /= 255.\n",
        "print(plot_img.shape)\n",
        "plt.imshow(plot_img, cmap = 'gray')\n",
        "print(\"Original Image\\n\")\n",
        "plt.show()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n",
            "(28, 28, 1)\n",
            "[[-314.47043  -257.08362  -119.184555   14.213372  354.9554    -12.627879\n",
            "  -332.2526   -159.64139   158.84584   555.5574  ]]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "(28, 28)\n",
            "Original Image\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAE69JREFUeJzt3W2MVGWWB/D/AXmRF6G7wbYFFBwI\niYphtEM0EjOrO4QxJDgf1OETm0yGMRmTHTOJa9wPa+IHzWZnJn7YTNKzkkEz68wmg5FEw6BkEyHZ\nqC1RgUFU3qRbupv37gaEbvrsh7ptWux7TlFPVd1izv+XEJo6fes+fasOVdXnOc8jqgoiimdC0QMg\nomIw+YmCYvITBcXkJwqKyU8UFJOfKCgmP1FQTH6ioJj8REFdV8+TiQinE45DRJLi1ixNbwand9+p\nrPPX+tyW1JmtqWOv5cxaVS1rcEnJLyKrAbwEYCKA/1LVF1Pu7++V90SZOnWqGZ84caIZHx4ezo1d\nvHjRPHbSpElmPPU/j6GhodzYddfZT7+U//Q81jUr5769sXtx67p4Ll++nBu7mmtS8dt+EZkI4D8B\n/AjA7QDWicjtld4fEdVXymf+FQC+UNWDqnoJwJ8ArK3OsIio1lKSfx6Ao2P+3ZXd9i0iskFEOkWk\nM+FcRFRlNf+Fn6p2AOgA+As/okaS8srfDWDBmH/Pz24jomtASvJ/AGCJiCwSkckAfgJgS3WGRUS1\nVvHbflUdFpEnAfwVpVLfRlXdW7WRjWPChPz/q0ZGRio+FvBLM1YJxSuXpZ57ypQpZvz8+fMVn9u7\nb69UaJ3b45WlvBKoV66zSoWpZUQv7l036/lar/kPSZ/5VfUtAG9VaSxEVEec3ksUFJOfKCgmP1FQ\nTH6ioJj8REEx+YmCqms/P+DXnWt1rNcW6923VZdNmSMAAF9//bUZ9+7fqnd7tfDJkyeb8dTWVqtm\n7d33hQsXzPi0adPMuPezW1L77b3reunSpdyYN2elWvjKTxQUk58oKCY/UVBMfqKgmPxEQTH5iYKS\nWi4h/J2TiahVUvPKcSmtjl4pzysLWW27XsnJWm21nHN7pR+rVOgde/3115txr9zmsR6zlBJmOazn\nU+rKwV7cK/X19/ebcYv3mJa7dDdf+YmCYvITBcXkJwqKyU8UFJOfKCgmP1FQTH6ioBqqpder81tS\nl+72lolOWWrZW8bZa+lNXeLa4s1BSDV79uzcmPdzp+6km9Lq7LnhhhvMuPezWc/1Wj8mo/jKTxQU\nk58oKCY/UVBMfqKgmPxEQTH5iYJi8hMFlVTnF5HDAAYAXAYwrKrtzvebfdTeVtdWXderjXo1YW8e\ngFW3TdmmuhwtLS1m/K677qr4vq0lpAH/MfHWA2htbc2NebXynTt3mvFdu3aZcYs37pT1HQB/zoo1\n96Nedf5qTPL5B1U9UYX7IaI64tt+oqBSk18BbBORD0VkQzUGRET1kfq2f6WqdovIjQDeFpFPVfXd\nsd+Q/afA/xiIGkzSK7+qdmd/9wF4HcCKcb6nQ1XbVbU9ZQFOIqquipNfRKaLyMzRrwGsArCnWgMj\notpKedvfCuD17NX8OgD/rapbqzIqIqq5uq7bP2HCBPXqoxZrjsDQ0JB5bGrtNGXb5IULF5rxRYsW\nmfGZM2ea8QMHDuTGDh06ZB6b0ncO+Nfd0tbWZsaXLVtmxnfv3m3GBwYGcmMpayAA/hoO3nWx5ld4\nx3pxrttPRCYmP1FQTH6ioJj8REEx+YmCYvITBVXXpbtV1SxTpLT0euWPlPsGgFmzZuXGli5dah7r\nta7u37/fjB85csSM11JKidNz7NgxM+49ps3NzWbcasv1th73Wp29uFcKtMrWKduDX03pnq/8REEx\n+YmCYvITBcXkJwqKyU8UFJOfKCgmP1FQdd+i26pDpmyz7S3F7G2TPX36dDN+880358a8ce/YscOM\nezXnFKtXrzbjW7emLcGwePFiM261DHd1dZnHnjhhLwrttRtbdf7BwUHzWK/l15u7kbJ9eL3a7PnK\nTxQUk58oKCY/UVBMfqKgmPxEQTH5iYJi8hMFVfc6v8XbFnnGjBm5Ma+/2qvFezXjnp6e3JjVm13O\nfae6++67c2O13iVp+fLlZnzPnuL2cZk8eXJurKmpyTzWq+N71/Xs2bNmPGUpefbzE1ESJj9RUEx+\noqCY/ERBMfmJgmLyEwXF5CcKyq3zi8hGAGsA9KnqndltzQD+DGAhgMMAHlPV0+Wc0OrJT6mHe1tN\nW+cF/DXgb7nlltyYVU8GgPfff9+Me1atWmXG77nnntyYtz34888/b8ZbWlrM+AsvvGDGv/rqq9yY\n1zPvPWb9/f1m3Ho+zZ492zzW2+fhzJkzZtzbc8D62bz5LtXq9y/nlf8PAK5cEeIZANtVdQmA7dm/\niega4ia/qr4L4NQVN68FsCn7ehOAR6o8LiKqsUo/87eq6uheSz0AWqs0HiKqk+S5/aqqIpL7IURE\nNgDYkHoeIqquSl/5e0WkDQCyv/vyvlFVO1S1XVXbKzwXEdVApcm/BcD67Ov1AN6oznCIqF7c5BeR\n1wD8H4ClItIlIj8F8CKAH4rI5wD+Mfs3EV1D3M/8qrouJ/TQ1Z5MRMzaq1dbtXr2vdrnlClTzPip\nU1cWNL5t/vz5uTGvHu3VhD3WHAMA2Lx5c27Mq4V7axEcPXrUjHv7JTz0UP7TZO7cueax27ZtM+Pd\n3d1m3JpH4F0X7/nk9fOnrB/RSHV+Ivo7xOQnCorJTxQUk58oKCY/UVBMfqKg6rp0t6qaSxZ7JQyr\nddYrvXhtt15p5sCBA7kxr+X2qaeeSjr33r17zfj+/fvNeC21tbWZ8WXLluXGvJ+rry934mhZrMfc\nW+rdi3tbug8MDJhx6zFPWdb7avCVnygoJj9RUEx+oqCY/ERBMfmJgmLyEwXF5CcKSqrVHljWyYzl\nvgC/NTZlaW+vpddb+ttqs/TmEDz44INm/PHHHzfjx48fN+NPP/20GbdY7cCA32a9c+dOM27V8js7\nO81jrW3RAX8bbWvs3nNt1qxZZnxwcNCM9/b2mvFa5p2qlrUvO1/5iYJi8hMFxeQnCorJTxQUk58o\nKCY/UVBMfqKg6trP75k2bZoZt3qgvTq+t/z12bNnzbjVW37hwgXz2HfeeceMe3X8Rx991Ixb18Vb\n5+CJJ54w46+++qoZnzlzphlfsmRJbszrifekbIPtzV84d+6cGT958qQZ97Yft+aVePNZUtbEGIuv\n/ERBMfmJgmLyEwXF5CcKislPFBSTnygoJj9RUG4/v4hsBLAGQJ+q3pnd9hyAnwEYLVA/q6pvuScT\nUavu7NVerfqnt9W01/vt1aubm5tzY95aAHv27DHj3hrxTU1NZtz62U+fPm0e620H7fG26L711ltz\nY5999pl5rLefgcdaZ8Grw3vXxYt7j6nFu6bW/Ibh4eGq9vP/AcDqcW7/raouz/64iU9EjcVNflV9\nF8CpOoyFiOoo5TP/kyLyiYhsFBH7fSkRNZxKk/93AL4HYDmAYwB+nfeNIrJBRDpFxF6wjYjqqqLk\nV9VeVb2sqiMAfg9ghfG9HararqrtlQ6SiKqvouQXkbFbs/4YgP3rbCJqOG5Lr4i8BuAHAOaISBeA\nfwPwAxFZDkABHAbw8xqOkYhqwE1+VV03zs0vV3pCa16B159t9ex7e5pfvHjRjHt1X+vcLS0t5rEH\nDx40415N2KvV15K3xoK3vr3VF5+6T4P3fLHG7t13f3+/GffG7s07sZ5v3pwTay0Bb/2GsTjDjygo\nJj9RUEx+oqCY/ERBMfmJgmLyEwVV1y26J0yYoFbbrld+sdoovZ9j9uzZZtxro7RKO/fee6957Jo1\na8y412788ccfm/Evv/wyN+a1SX/66adm3CuhdnV1mXFrWXKvFdobe8rS317p1yv1eduye89lqyTn\ntTJbpeGRkRFu0U1ENiY/UVBMfqKgmPxEQTH5iYJi8hMFxeQnCqrudX6r1dFbDtkaq1cTnjNnjhk/\nceKEGbd4raWLFy8248uWLTPjXsuwVWs/f/68eay3FfW+ffvMuHf/Kby5F95zd+7cubkxb0t2r83a\na+n1jk9dMt3COj8RmZj8REEx+YmCYvITBcXkJwqKyU8UFJOfKKi61vlFRK36aEo/v9ev7xkcHDTj\nXi2frp63vLU3d8Nbptrq979w4YJ5rLeOQcrci1TWdRkeHsbIyAjr/ESUj8lPFBSTnygoJj9RUEx+\noqCY/ERBMfmJgnK36BaRBQBeAdAKQAF0qOpLItIM4M8AFgI4DOAxVXX3krbmFXg9zlZd2KsZe+us\ne/3dKbxze7zecItXC29ubjbj3vr23hrz1s/uPd6pPe/WVtfengHe1uPz5s0z4976EN75LdYchKuZ\nt1POK/8wgF+p6u0A7gXwCxG5HcAzALar6hIA27N/E9E1wk1+VT2mqruyrwcA7AMwD8BaAJuyb9sE\n4JFaDZKIqu+qPvOLyEIA3wfwHoBWVT2WhXpQ+lhARNcI9zP/KBGZAeAvAH6pqv1jP0uqqorIuB82\nRGQDgA2pAyWi6irrlV9EJqGU+H9U1c3Zzb0i0pbF2wD0jXesqnaoaruqtldjwERUHW7yS+kl/mUA\n+1T1N2NCWwCsz75eD+CN6g+PiGrFbekVkZUAdgDYDWC0rvMsSp/7/wfALQCOoFTqO+Xcl1qlJ6+l\n1yor3XjjjeaxXnvo0aNHzbg1bu++rZIT4LePestj33///bmxqVOnmsdu3brVjHvPD28Ja68UmMK7\n7lYZs7e31zzWu24PPPCAGfeuy+7du3NjfX3jvon+hlcuL3fpbvczv6ruBJB3Zw+VcxIiajyc4UcU\nFJOfKCgmP1FQTH6ioJj8REEx+YmCqvvS3VbrrVcbtZZiTm3Z9dpHrRZPr97sXeOlS5ea8TvuuMOM\nHzp0KDf23nvvmceePu12YV+zpk2blhvznmveUu633XabGb/vvvvMuNUq/eabb5rHesuOc4tuIjIx\n+YmCYvITBcXkJwqKyU8UFJOfKCgmP1FQda/zW33x3vLb1jbcXt/4yZMnzbhXq58xY0ZuzNuu2asp\ne3MUzpw5Y8atOQxTpkwxj73pppvMuPf88NZB6O/vN+NFmTNnjhn3ltb21mDwlky35pWkLNUOsM5P\nRA4mP1FQTH6ioJj8REEx+YmCYvITBcXkJwqqoer8Xq3dqod7df4yeqDNeFNTU27Mq/N767B76/J7\n6/5btXxvjoA3x8CbB+DNYbDmR/T09JjH1nKba2/c3pwT7/iUsXmsHFJV1vmJyMbkJwqKyU8UFJOf\nKCgmP1FQTH6ioJj8REG5dX4RWQDgFQCtABRAh6q+JCLPAfgZgOPZtz6rqm8595VU57dqq16df2ho\nyIx7dV1rzwDv3F5Pe2rN2dtzwOKN3Vr7HvDnIFjXzZvf4D1m3tyNWvbM15K3FoDlaur89rOqZBjA\nr1R1l4jMBPChiLydxX6rqv9R6UCJqDhu8qvqMQDHsq8HRGQfgHm1HhgR1dZVfeYXkYUAvg9gdA+o\nJ0XkExHZKCLjzn8VkQ0i0ikinUkjJaKqKjv5RWQGgL8A+KWq9gP4HYDvAViO0juDX493nKp2qGq7\nqrZXYbxEVCVlJb+ITEIp8f+oqpsBQFV7VfWyqo4A+D2AFbUbJhFVm5v8UvrV48sA9qnqb8bc3jbm\n234MYE/1h0dEtVJOqW8lgB0AdgMYrQs9C2AdSm/5FcBhAD/Pfjlo3ZdZ6kspcUycODEp7pUZrbGl\ntm965TZvmWjrZ/PKhNZW0YDf6pxi6tSpZtwrI547d86Mp1wXrxXauy7e88niPd7e86VqpT5V3Qlg\nvDsza/pE1Ng4w48oKCY/UVBMfqKgmPxEQTH5iYJi8hMFVfelu2t432bcq+t6dVmrtuq11Hp1W089\nH6N68lqZvXkA3nW37t9bstzjPSZeO7L1nPB+Lu/cXLqbiExMfqKgmPxEQTH5iYJi8hMFxeQnCorJ\nTxRUvev8xwEcGXPTHAD2PszFadSxNeq4AI6tUtUc262qOrecb6xr8n/n5CKdjbq2X6OOrVHHBXBs\nlSpqbHzbTxQUk58oqKKTv6Pg81sadWyNOi6AY6tUIWMr9DM/ERWn6Fd+IipIIckvIqtFZL+IfCEi\nzxQxhjwiclhEdovIR0VvMZZtg9YnInvG3NYsIm+LyOfZ3+Nuk1bQ2J4Tke7s2n0kIg8XNLYFIvK/\nIvI3EdkrIv+c3V7otTPGVch1q/vbfhGZCOAzAD8E0AXgAwDrVPVvdR1IDhE5DKBdVQuvCYvIAwAG\nAbyiqndmt/07gFOq+mL2H2eTqv5Lg4ztOQCDRe/cnG0o0zZ2Z2kAjwD4JxR47YxxPYYCrlsRr/wr\nAHyhqgdV9RKAPwFYW8A4Gp6qvgvg1BU3rwWwKft6E0pPnrrLGVtDUNVjqror+3oAwOjO0oVeO2Nc\nhSgi+ecBODrm311orC2/FcA2EflQRDYUPZhxtI7ZGakHQGuRgxmHu3NzPV2xs3TDXLtKdryuNv7C\n77tWqurdAH4E4BfZ29uGpKXPbI1Urilr5+Z6GWdn6W8Uee0q3fG62opI/m4AC8b8e352W0NQ1e7s\n7z4Ar6Pxdh/uHd0kNfu7r+DxfKORdm4eb2dpNMC1a6Qdr4tI/g8ALBGRRSIyGcBPAGwpYBzfISLT\ns1/EQESmA1iFxtt9eAuA9dnX6wG8UeBYvqVRdm7O21kaBV+7htvxWlXr/gfAwyj9xv8AgH8tYgw5\n47oNwMfZn71Fjw3Aayi9DRxC6XcjPwXQAmA7gM8BvAOguYHG9ipKuzl/glKitRU0tpUovaX/BMBH\n2Z+Hi752xrgKuW6c4UcUFH/hRxQUk58oKCY/UVBMfqKgmPxEQTH5iYJi8hMFxeQnCur/ASkMoHpd\nd/gqAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "z4E1RHEx_huI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1703
        },
        "outputId": "d7d6e2e9-b2ef-4dac-f93c-4510db76058e"
      },
      "cell_type": "code",
      "source": [
        "mnist_model_distillation = train_distillation(MNIST(), \"models/mnist-distilled-100\", [32, 32, 64, 64, 200, 200],\n",
        "                   num_epochs=20, train_temp=100)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(55000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/20\n",
            "55000/55000 [==============================] - 4s 71us/step - loss: 0.4404 - acc: 0.9282 - val_loss: 0.1016 - val_acc: 0.9702\n",
            "Epoch 2/20\n",
            "55000/55000 [==============================] - 3s 59us/step - loss: 0.1357 - acc: 0.9583 - val_loss: 0.0803 - val_acc: 0.9764\n",
            "Epoch 3/20\n",
            "55000/55000 [==============================] - 3s 61us/step - loss: 0.1082 - acc: 0.9667 - val_loss: 0.0694 - val_acc: 0.9802\n",
            "Epoch 4/20\n",
            "55000/55000 [==============================] - 3s 64us/step - loss: 0.0936 - acc: 0.9715 - val_loss: 0.0637 - val_acc: 0.9798\n",
            "Epoch 5/20\n",
            "55000/55000 [==============================] - 4s 65us/step - loss: 0.0847 - acc: 0.9743 - val_loss: 0.0558 - val_acc: 0.9838\n",
            "Epoch 6/20\n",
            "55000/55000 [==============================] - 3s 63us/step - loss: 0.0754 - acc: 0.9768 - val_loss: 0.0538 - val_acc: 0.9844\n",
            "Epoch 7/20\n",
            "55000/55000 [==============================] - 3s 59us/step - loss: 0.0697 - acc: 0.9783 - val_loss: 0.0541 - val_acc: 0.9868\n",
            "Epoch 8/20\n",
            "55000/55000 [==============================] - 3s 59us/step - loss: 0.0653 - acc: 0.9802 - val_loss: 0.0466 - val_acc: 0.9872\n",
            "Epoch 9/20\n",
            "55000/55000 [==============================] - 3s 59us/step - loss: 0.0618 - acc: 0.9811 - val_loss: 0.0466 - val_acc: 0.9874\n",
            "Epoch 10/20\n",
            "55000/55000 [==============================] - 3s 59us/step - loss: 0.0564 - acc: 0.9832 - val_loss: 0.0457 - val_acc: 0.9864\n",
            "Epoch 11/20\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0541 - acc: 0.9833 - val_loss: 0.0459 - val_acc: 0.9874\n",
            "Epoch 12/20\n",
            "55000/55000 [==============================] - 3s 59us/step - loss: 0.0490 - acc: 0.9849 - val_loss: 0.0437 - val_acc: 0.9876\n",
            "Epoch 13/20\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0473 - acc: 0.9855 - val_loss: 0.0425 - val_acc: 0.9880\n",
            "Epoch 14/20\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0454 - acc: 0.9856 - val_loss: 0.0416 - val_acc: 0.9892\n",
            "Epoch 15/20\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0426 - acc: 0.9864 - val_loss: 0.0410 - val_acc: 0.9884\n",
            "Epoch 16/20\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0415 - acc: 0.9869 - val_loss: 0.0415 - val_acc: 0.9884\n",
            "Epoch 17/20\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0377 - acc: 0.9881 - val_loss: 0.0437 - val_acc: 0.9890\n",
            "Epoch 18/20\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0379 - acc: 0.9880 - val_loss: 0.0416 - val_acc: 0.9888\n",
            "Epoch 19/20\n",
            "55000/55000 [==============================] - 3s 59us/step - loss: 0.0356 - acc: 0.9891 - val_loss: 0.0374 - val_acc: 0.9898\n",
            "Epoch 20/20\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0338 - acc: 0.9895 - val_loss: 0.0381 - val_acc: 0.9900\n",
            "[[2.8270912e-07 1.2298473e-05 2.4601230e-02 ... 8.9799130e-01\n",
            "  1.6574077e-05 8.2755077e-04]\n",
            " [3.1858442e-15 1.4858497e-13 5.9368336e-13 ... 1.2779218e-14\n",
            "  3.5038799e-08 7.5811778e-07]\n",
            " [1.8518610e-11 1.3066004e-07 3.4320177e-10 ... 1.7056223e-07\n",
            "  1.6571372e-06 2.2343041e-01]\n",
            " ...\n",
            " [1.4200673e-11 9.0509387e-13 7.4256589e-16 ... 6.0870629e-15\n",
            "  5.4248983e-09 1.7176632e-06]\n",
            " [3.4090592e-06 1.0858936e-11 2.0288500e-09 ... 1.4971924e-14\n",
            "  1.8192090e-08 4.0897570e-11]\n",
            " [6.3365127e-07 2.9842961e-10 2.2890802e-08 ... 1.1846197e-09\n",
            "  9.9999666e-01 2.6145310e-06]]\n",
            "(55000, 28, 28, 1)\n",
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/20\n",
            "55000/55000 [==============================] - 4s 68us/step - loss: 0.4300 - acc: 0.9306 - val_loss: 0.1024 - val_acc: 0.9674\n",
            "Epoch 2/20\n",
            "55000/55000 [==============================] - 3s 59us/step - loss: 0.1225 - acc: 0.9622 - val_loss: 0.0766 - val_acc: 0.9778\n",
            "Epoch 3/20\n",
            "55000/55000 [==============================] - 3s 59us/step - loss: 0.0969 - acc: 0.9703 - val_loss: 0.0660 - val_acc: 0.9800\n",
            "Epoch 4/20\n",
            "55000/55000 [==============================] - 3s 59us/step - loss: 0.0820 - acc: 0.9750 - val_loss: 0.0641 - val_acc: 0.9804\n",
            "Epoch 5/20\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0727 - acc: 0.9775 - val_loss: 0.0565 - val_acc: 0.9834\n",
            "Epoch 6/20\n",
            "55000/55000 [==============================] - 3s 59us/step - loss: 0.0656 - acc: 0.9803 - val_loss: 0.0532 - val_acc: 0.9850\n",
            "Epoch 7/20\n",
            "55000/55000 [==============================] - 3s 61us/step - loss: 0.0603 - acc: 0.9824 - val_loss: 0.0537 - val_acc: 0.9842\n",
            "Epoch 8/20\n",
            "55000/55000 [==============================] - 3s 63us/step - loss: 0.0556 - acc: 0.9843 - val_loss: 0.0507 - val_acc: 0.9852\n",
            "Epoch 9/20\n",
            "55000/55000 [==============================] - 3s 63us/step - loss: 0.0508 - acc: 0.9856 - val_loss: 0.0487 - val_acc: 0.9854\n",
            "Epoch 10/20\n",
            "55000/55000 [==============================] - 3s 60us/step - loss: 0.0492 - acc: 0.9864 - val_loss: 0.0454 - val_acc: 0.9878\n",
            "Epoch 11/20\n",
            "55000/55000 [==============================] - 3s 59us/step - loss: 0.0462 - acc: 0.9873 - val_loss: 0.0474 - val_acc: 0.9868\n",
            "Epoch 12/20\n",
            "55000/55000 [==============================] - 3s 59us/step - loss: 0.0451 - acc: 0.9876 - val_loss: 0.0492 - val_acc: 0.9866\n",
            "Epoch 13/20\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0437 - acc: 0.9883 - val_loss: 0.0469 - val_acc: 0.9870\n",
            "Epoch 14/20\n",
            "55000/55000 [==============================] - 3s 59us/step - loss: 0.0415 - acc: 0.9889 - val_loss: 0.0451 - val_acc: 0.9872\n",
            "Epoch 15/20\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0399 - acc: 0.9896 - val_loss: 0.0445 - val_acc: 0.9878\n",
            "Epoch 16/20\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0388 - acc: 0.9901 - val_loss: 0.0447 - val_acc: 0.9878\n",
            "Epoch 17/20\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0381 - acc: 0.9906 - val_loss: 0.0445 - val_acc: 0.9892\n",
            "Epoch 18/20\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0372 - acc: 0.9913 - val_loss: 0.0459 - val_acc: 0.9876\n",
            "Epoch 19/20\n",
            "55000/55000 [==============================] - 3s 58us/step - loss: 0.0358 - acc: 0.9917 - val_loss: 0.0439 - val_acc: 0.9876\n",
            "Epoch 20/20\n",
            "55000/55000 [==============================] - 3s 59us/step - loss: 0.0351 - acc: 0.9917 - val_loss: 0.0444 - val_acc: 0.9876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RuxfEtNPAFnm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d8777032-5bd0-45c6-a15d-1b37c06f3c38"
      },
      "cell_type": "code",
      "source": [
        "print(mnist_model_distillation.predict(og))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-11368.487    5554.8013  -4420.0356   2939.328    4802.76    -4766.2007\n",
            "  -13194.854    -745.6022   8549.191    9542.696 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CHbsH9QyAx9S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hacking Trained CNN for CIFAR"
      ]
    },
    {
      "metadata": {
        "id": "h-r08UTWAxGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "8e587b60-fd30-421f-c84a-9764bac8c47c"
      },
      "cell_type": "code",
      "source": [
        "import foolbox\n",
        "from foolbox.models import TensorFlowModel, KerasModel\n",
        "from foolbox.attacks import LBFGSAttack\n",
        "from foolbox.attacks import DeepFoolAttack, BIM, GradientAttack\n",
        "from foolbox.criteria import TargetClassProbability\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "#from keras.applications.resnet50 import decode_predictions\n",
        "\n",
        "#keras.backend.set_learning_phase(0)\n",
        "#kmodel = ResNet50(weights='imagenet')\n",
        "#fmodel = KerasModel(model, bounds=(0, 255), preprocessing=preprocessing)\n",
        "\n",
        "#preprocessing = (np.array([104, 116, 123]), 1)\n",
        "# print(cifar_model.summary())\n",
        "\n",
        "# print(data.validation_data[28])\n",
        "fmodel = KerasModel(cifar_model, bounds=(0, 255), predicts='logits')\n",
        "\n",
        "\n",
        "image = data.validation_data[28] #Do not put test_img since it has been expanded\n",
        "print(data.validation_labels[28])\n",
        "label = 11\n",
        "\n",
        "# run the attack\n",
        "attack = LBFGSAttack(model=fmodel, criterion=TargetClassProbability(10, p=.5))\n",
        "# attack = BIM(model=fmodel, criterion=TargetClassProbability(10, p=.99))\n",
        "# attack = GradientAttack(model=fmodel, criterion=TargetClassProbability(10, p=.5))\n",
        "\n",
        "# attack = DeepFoolAttack(model=fmodel, criterion=TargetClassProbability(1, p=.2))\n",
        "\n",
        "adversarial = attack(image[:, :, :], label) #image[:, :, ::-1] For BGR\n",
        "\n",
        "# show results\n",
        "print(np.argmax(fmodel.predictions(adversarial)))\n",
        "print(foolbox.utils.softmax(fmodel.predictions(adversarial))[2])\n",
        "adversarial_rgb = adversarial[np.newaxis, :, :, :] #image[:, :, ::-1] For BGR\n",
        "preds = model.predict(adversarial_rgb)\n",
        "\n",
        "print(\"Prediction: \", preds)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-2dff1749805e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# attack = DeepFoolAttack(model=fmodel, criterion=TargetClassProbability(1, p=.2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0madversarial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#image[:, :, ::-1] For BGR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# show results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/foolbox/attacks/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, input_or_adv, label, unpack, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m                                      ' instance.')\n\u001b[1;32m    123\u001b[0m                 a = Adversarial(model, criterion, input_or_adv, label,\n\u001b[0;32m--> 124\u001b[0;31m                                 distance=distance, threshold=threshold)\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/foolbox/adversarial.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, criterion, original_image, original_class, distance, threshold, verbose)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# check if the original image is already adversarial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopAttack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# if a threshold is specified and the original input is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/foolbox/adversarial.py\u001b[0m in \u001b[0;36mpredictions\u001b[0;34m(self, image, strict, return_details)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \"\"\"\n\u001b[1;32m    301\u001b[0m         \u001b[0min_bounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstrict\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0min_bounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_prediction_calls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "J_ZCfPyuAP4u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_distillation(CIFAR(), \"models/cifar-distilled-100\", [64, 64, 128, 128, 256, 256],\n",
        "                   num_epochs=50, train_temp=100)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}